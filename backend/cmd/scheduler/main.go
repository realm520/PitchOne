package main

import (
	"context"
	"database/sql"
	"flag"
	"fmt"
	"log"
	"os"
	"os/signal"
	"syscall"
	"time"

	"github.com/ethereum/go-ethereum/common"
	"github.com/pitchone/sportsbook/internal/rewards"
	"github.com/robfig/cron/v3"
	_ "github.com/lib/pq"
)

// Config è°ƒåº¦å™¨é…ç½®
type Config struct {
	DatabaseURL     string
	RPCURL          string
	DistributorAddr string
	PrivateKey      string
	TestMode        bool  // æµ‹è¯•æ¨¡å¼ï¼šç«‹å³æ‰§è¡Œä¸€æ¬¡
	CronSchedule    string // Cron è¡¨è¾¾å¼
}

// Scheduler å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
type Scheduler struct {
	config     *Config
	db         *sql.DB
	aggregator *rewards.Aggregator
	publisher  *rewards.Publisher
	cron       *cron.Cron
}

func main() {
	// è§£æé…ç½®
	config := parseFlags()

	// åˆ›å»ºè°ƒåº¦å™¨
	scheduler, err := NewScheduler(config)
	if err != nil {
		log.Fatalf("Failed to create scheduler: %v", err)
	}
	defer scheduler.Close()

	// æµ‹è¯•æ¨¡å¼ï¼šç«‹å³æ‰§è¡Œä¸€æ¬¡
	if config.TestMode {
		log.Println("ğŸ§ª Test mode: running weekly rewards task once")
		if err := scheduler.runWeeklyRewards(); err != nil {
			log.Fatalf("Test run failed: %v", err)
		}
		log.Println("âœ… Test run completed successfully")
		return
	}

	// å¯åŠ¨å®šæ—¶ä»»åŠ¡
	scheduler.Start()

	log.Printf("ğŸš€ Scheduler started (cron: %s)", config.CronSchedule)
	log.Println("Press Ctrl+C to stop")

	// ä¼˜é›…é€€å‡º
	quit := make(chan os.Signal, 1)
	signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)
	<-quit

	log.Println("Shutting down scheduler...")
	scheduler.Stop()
	log.Println("âœ… Scheduler stopped")
}

// NewScheduler åˆ›å»ºè°ƒåº¦å™¨
func NewScheduler(config *Config) (*Scheduler, error) {
	// è¿æ¥æ•°æ®åº“
	db, err := sql.Open("postgres", config.DatabaseURL)
	if err != nil {
		return nil, fmt.Errorf("failed to connect to database: %w", err)
	}

	if err := db.Ping(); err != nil {
		return nil, fmt.Errorf("failed to ping database: %w", err)
	}

	log.Println("âœ… Connected to database")

	// åˆ›å»ºèšåˆå™¨
	aggregator := rewards.NewAggregator(db)

	// åˆ›å»ºå‘å¸ƒå™¨ï¼ˆå¦‚æœé…ç½®äº† RPCï¼‰
	var publisher *rewards.Publisher
	if config.RPCURL != "" && config.DistributorAddr != "" && config.PrivateKey != "" {
		publisher, err = rewards.NewPublisher(
			config.RPCURL,
			common.HexToAddress(config.DistributorAddr),
			config.PrivateKey,
		)
		if err != nil {
			return nil, fmt.Errorf("failed to create publisher: %w", err)
		}
		log.Println("âœ… Connected to blockchain")
	} else {
		log.Println("âš ï¸  No RPC config - rewards will be aggregated but not published to chain")
	}

	// åˆ›å»º Cron è°ƒåº¦å™¨
	c := cron.New(cron.WithSeconds()) // æ”¯æŒç§’çº§ç²¾åº¦ï¼ˆç”¨äºæµ‹è¯•ï¼‰

	return &Scheduler{
		config:     config,
		db:         db,
		aggregator: aggregator,
		publisher:  publisher,
		cron:       c,
	}, nil
}

// Start å¯åŠ¨å®šæ—¶ä»»åŠ¡
func (s *Scheduler) Start() {
	// æ·»åŠ å‘¨åº¦å¥–åŠ±ä»»åŠ¡
	// é»˜è®¤ï¼šæ¯å‘¨æ—¥ 23:59:00 æ‰§è¡Œ
	_, err := s.cron.AddFunc(s.config.CronSchedule, s.runWeeklyRewardsWithRecover)
	if err != nil {
		log.Fatalf("Failed to add cron job: %v", err)
	}

	// æ·»åŠ å¥åº·æ£€æŸ¥ä»»åŠ¡ï¼ˆæ¯å¤© 00:05:00 æ£€æŸ¥å¤±è´¥çš„ä»»åŠ¡ï¼‰
	_, err = s.cron.AddFunc("0 5 0 * * *", s.checkFailedTasks)
	if err != nil {
		log.Printf("Failed to add health check job: %v", err)
	}

	s.cron.Start()
}

// Stop åœæ­¢å®šæ—¶ä»»åŠ¡
func (s *Scheduler) Stop() {
	s.cron.Stop()
}

// Close å…³é—­è¿æ¥
func (s *Scheduler) Close() {
	if s.db != nil {
		s.db.Close()
	}
	if s.publisher != nil {
		s.publisher.Close()
	}
}

// runWeeklyRewardsWithRecover æ‰§è¡Œå‘¨åº¦å¥–åŠ±ä»»åŠ¡ï¼ˆå¸¦æ¢å¤ï¼‰
func (s *Scheduler) runWeeklyRewardsWithRecover() {
	defer func() {
		if r := recover(); r != nil {
			log.Printf("âŒ Panic recovered: %v", r)
			// TODO: å‘é€å‘Šè­¦é€šçŸ¥
		}
	}()

	if err := s.runWeeklyRewards(); err != nil {
		log.Printf("âŒ Weekly rewards task failed: %v", err)
		// TODO: å‘é€å‘Šè­¦é€šçŸ¥
	}
}

// runWeeklyRewards æ‰§è¡Œå‘¨åº¦å¥–åŠ±ä»»åŠ¡
func (s *Scheduler) runWeeklyRewards() error {
	ctx := context.Background()

	// ç¡®å®šè¦å¤„ç†çš„å‘¨
	week := rewards.GetCurrentWeek() - 1 // å¤„ç†ä¸Šä¸€å‘¨
	log.Printf("ğŸ•’ Starting weekly rewards task for week %d", week)

	// 1. æ£€æŸ¥æ˜¯å¦å·²å‘å¸ƒ
	existing, _ := s.aggregator.GetDistribution(ctx, week)
	if existing != nil {
		log.Printf("âš ï¸  Week %d already processed (root: %s), skipping", week, existing.Root)
		return nil
	}

	// 2. èšåˆå¥–åŠ±æ•°æ®
	log.Printf("ğŸ“Š Aggregating rewards for week %d...", week)
	startTime := time.Now()

	entries, err := s.aggregator.AggregateWeeklyRewards(ctx, week)
	if err != nil {
		return fmt.Errorf("failed to aggregate rewards: %w", err)
	}

	log.Printf("âœ… Aggregated %d reward entries in %v", len(entries), time.Since(startTime))

	if len(entries) == 0 {
		log.Printf("âš ï¸  No rewards to distribute for week %d", week)
		return nil
	}

	// 3. ç”Ÿæˆ Merkle åˆ†é…
	log.Printf("ğŸŒ³ Building Merkle tree...")
	scaleBps := uint64(10000) // TODO: ä»åˆçº¦æŸ¥è¯¢å¯ç”¨é¢„ç®—å¹¶è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
	distribution, err := rewards.BuildDistribution(week, entries, scaleBps)
	if err != nil {
		return fmt.Errorf("failed to build distribution: %w", err)
	}

	distribution.CreatedAt = time.Now().Unix()

	log.Printf("âœ… Merkle Root: %s", distribution.Root)
	log.Printf("   Recipients: %d", distribution.Recipients)
	log.Printf("   Total Amount: %s", distribution.TotalAmount)
	log.Printf("   Scale: %d bps (%.2f%%)", distribution.ScaleBps, float64(distribution.ScaleBps)/100)

	// 4. ä¿å­˜åˆ°æ•°æ®åº“
	if err := s.aggregator.SaveDistribution(ctx, distribution); err != nil {
		return fmt.Errorf("failed to save distribution: %w", err)
	}

	log.Printf("âœ… Distribution saved to database")

	// 5. å‘å¸ƒåˆ°é“¾ä¸Šï¼ˆå¦‚æœé…ç½®äº† Publisherï¼‰
	if s.publisher != nil {
		log.Printf("ğŸ“¤ Publishing to blockchain...")

		tx, err := s.publisher.PublishRoot(ctx, distribution)
		if err != nil {
			return fmt.Errorf("failed to publish root: %w", err)
		}

		log.Printf("âœ… Transaction sent: %s", tx.Hash().Hex())

		// ç­‰å¾…ç¡®è®¤
		log.Printf("â³ Waiting for confirmation...")
		receipt, err := s.publisher.WaitForConfirmation(ctx, tx, 3)
		if err != nil {
			return fmt.Errorf("transaction failed: %w", err)
		}

		log.Printf("âœ… Transaction confirmed in block %d", receipt.BlockNumber.Uint64())
		log.Printf("   Gas used: %d", receipt.GasUsed)

		// éªŒè¯é“¾ä¸Šæ•°æ®
		publishedRoot, err := s.publisher.GetPublishedRoot(ctx, week)
		if err != nil {
			log.Printf("âš ï¸  Failed to verify published root: %v", err)
		} else if publishedRoot.Hex() != distribution.Root {
			return fmt.Errorf("root mismatch! Expected %s, got %s", distribution.Root, publishedRoot.Hex())
		} else {
			log.Printf("âœ… Root verified on-chain")
		}
	} else {
		log.Printf("âš ï¸  Skipping on-chain publication (no RPC config)")
	}

	log.Printf("ğŸ‰ Weekly rewards for week %d completed successfully!", week)
	// TODO: å‘é€æˆåŠŸé€šçŸ¥ï¼ˆSlack/Discordï¼‰

	return nil
}

// checkFailedTasks æ£€æŸ¥å¤±è´¥çš„ä»»åŠ¡
func (s *Scheduler) checkFailedTasks() {
	log.Println("ğŸ” Checking for failed tasks...")

	ctx := context.Background()
	currentWeek := rewards.GetCurrentWeek()

	// æ£€æŸ¥æœ€è¿‘ 4 å‘¨æ˜¯å¦æœ‰æœªå‘å¸ƒçš„å‘¨
	for i := uint64(1); i <= 4; i++ {
		week := currentWeek - i
		dist, err := s.aggregator.GetDistribution(ctx, week)
		if err != nil || dist == nil {
			log.Printf("âš ï¸  Week %d appears to be missing - consider manual intervention", week)
			// TODO: å‘é€å‘Šè­¦é€šçŸ¥
		}
	}
}

func parseFlags() *Config {
	config := &Config{}

	flag.StringVar(&config.DatabaseURL, "db", os.Getenv("DATABASE_URL"), "Database URL (env: DATABASE_URL)")
	flag.StringVar(&config.RPCURL, "rpc-url", os.Getenv("RPC_URL"), "Ethereum RPC URL (env: RPC_URL)")
	flag.StringVar(&config.DistributorAddr, "distributor", os.Getenv("REWARDS_DISTRIBUTOR_ADDR"), "RewardsDistributor contract address")
	flag.StringVar(&config.PrivateKey, "private-key", os.Getenv("PRIVATE_KEY"), "Private key for signing transactions")
	flag.BoolVar(&config.TestMode, "test", false, "Test mode: run once and exit")
	flag.StringVar(&config.CronSchedule, "cron", "0 59 23 * * 0", "Cron schedule (default: every Sunday 23:59:00)")

	flag.Parse()

	if config.DatabaseURL == "" {
		log.Fatal("DATABASE_URL is required")
	}

	return config
}
